threading
python gil(global interpreter lock)
	gil使得同一时刻只有一个线程在一个CPU上执行字节码，无法将多个线程映射到多CPU
	gil会根据执行的字节码行数以及时间片释放gill，gill在遇到io操作的时候主动释放
对于io操作来说，多线程和多进程的差别并不大，threading.join()是实现在线程执行完之后才执行之后的mainthreading操作；setDaemon()启动守护线程，mainthreading执行完之后便不再执行之后的操作
在代码量比较多的情况下通过类继承threading来实现编译
线程的通信方式：共享变量（安全性问题）
			 queue方式进行线程间同步，无安全性问题
			 queue的相关操作(put将数据写入队列，get从queue提取数据，qsize获取队列长度，empty判断队列是否为空，full判断队列是否已满，如果已满，put会阻塞，put默认block为true，这时可以设置一个timeout值，如果到达timeout时，队列就不会等待了，join阻塞队列，在执行tesk_done时才会退出阻塞状态)
线程同步问题：from threading import lock（必须acquire和release），这样导致的问题：运行时间比较慢，影响性能；容易引起死锁
			解决死锁问题（RLock，在同一个线程里面可以多次调用多次acquire，一定注意acquire的次数必须和release次数相同）
条件变量，用于复杂的线程间同步（from threading import Condition）
		wait：等待某个notify通知
		notify：通知wait
		condition中线程的启动顺序很重要，必须先调用wait线程
		在调用with之后才能调用wait方法或者notify方法
		condition有两层锁，一把底层锁会在线程调用了wait方法的时候释放，上面的锁会在每次调用wait的时候分配一把并放入到cond的等待队列中，等待notify方法的唤醒
可以通过semaphore限制多线程启动的数量（threading.Semaphore）
线程池（from concurrent.futures import ThreadPoolExecutor,as_completed,wait）：
		as_comlpeted是一个生成器
		wait(task)---等待task执行完成再执行后续操作，还可以执行执行了几个task之后再执行下面操作
	为什么要线程池：
	1.主线程中可以获取某一个线程的状态或者某一个任务的状态，以及返回值
	2.当一个线程完成的时候我们主线程立即知道
	3.futures可以让多线程和多进程编程接口一致
	excutor = ThreadPoolExcutor(max_workers=2)-----线程池同时运行大小
	task=excutor.submit(target,args)----通过submit函数提交执行的函数到线程池中
										submit是立即返回
	task.done()---判断是否执行成功
	task.result()----获取task的执行结果
	task.cancel()--- 取消task执行
	excutor.map(target,args) ---通过excutor获取已经完成的task
	from concurrent.futures import Future
	一般将Future定义为未来对象，指的是当前还没完成，有可能在未来完成的task


os.fork()----只适用于Linux/Unix，生成一个子进程，子进程会复制一份父进程数据，再重新执行
			 一次父进程的流程，加了sleep之后，父进程会等待子进程完成之后再退出
from concurrent.futures import ProcessPoolExcutor---多进程编程
import multiprocessing ---多进程编程，与多线程不同的多一个pid
使用进程池
pool = multiprocessing.Pool(进程个数) 默认为CPU个数--multiprocessing.cpu_count()
result = pool.apply_async(target,args)--异步提交任务
pool.close()
pool.join()---等待所有任务完成
result.get()
pool.imap()和pool.imap_unordered()对应线程池中的map
多进程通信：
	1.from multiprocessing import Queue,与多线程间类似
	2.共享全局变量不适用多进程编程，可以适用于多线程
	3.multiprocessing中的Queue不能用于pool进程池
	4.pool中的进程间通信需要使用manager中的queue（from multiprocessing import Manage）
	5.通过pipe实现进程间通信（from multiprocessing import Pipe）
		pipe只能适用于两个进程间通信
		recevie_pipe,send_pipe = Pipe()
	pipe的性能高于queue
	进程间内存共享：利用Manager函数中的数据类型，可以实现多个进程共享一个数据类型，例:process_dict = Manager().dict()

python一切皆对象
	函数和类也是对象：1.赋值给一个变量
					2.可以添加到集合对象中
					3.可以作为参数传递给函数
					4.可以当做函数的返回值
	type,object和class的关系:类是由type生成的一个对象
							object是最顶层的基类，是所有类型的基类，包括type，type是所有对象的实例，包括type自身和object
	None对象全局只有一个（id(None) == id(None)）
抽象基类:
	是通过继承的关系来限制子类必须做的一些操作，利用abc模块中来生成一个装饰器，可以实现对子类的必须操作

type和isinstance的区别:
	type的本质是判断两种类型的ID是否相等,比如 type(a) is A,而继承链的关系则没法通过这样来判断，isinstance是通过继承关系来判断的，而不用通过ID来比较

类变量与实例变量:
	实例就是类赋予的变量，类变量是位于构造函数之上的值，在检查实例变量时，默认会先检查构造函数的值，如果构造函数中不存在，会继续往上查找，还是不存在才会抛出异常，在外面修改类变量的值时，python会默认生成一个不存在的变量值，这个可以通过ID值查看，这导致了修改实例变量得到的值优先于类变量

多重继承查找顺序:默认查找顺序放在__mro__魔法函数中
Python的自省机制：通过一定的机制查询到对象的内部结构，可以通过__dict__来查询到对象内部的结构，以key，value的形式显示；还可以使用dir函数来查看对象内部的结构
super函数的查找顺序：super函数的默认查找顺序是按照mro顺序查找，在使用多继承的时候，想要规定super中父类的运行顺序，必须按照mro规定排序
上下文管理器：1.with语句实现上下文管理：利用魔法函数__enter__(获取资源)和__exit__(释放资源)来规划类中的运行顺序
		    2.利用contextlib中的contextlib.contextmanager生成一个装饰器，以yield来作为运行顺序的分界点

使用bisect维护一个排序序列：bisect中的insert插入时会自动排序
array和list最大的一个区别就是array只能存放一种数据类型的数据，查看array的方法可以查看array提供的官方接口
列表推导式：通过一行代码来生成列表，在保证代码可读性的情况下，列表推导式能用尽量用，列表推导式的性能高于列表操作

生成器表达式：将列表推导式中的[]换成()，就是生成器表达式，生成一个生成器，可以用for循环取值，生成器表达式可以用list()函数生成一个列表

字典推导式：利用dict.items生成

dict常用函数：1.copy浅拷贝，修改拷贝之后的值，被拷贝对象值也会改变，可引入copy中的deepco
			  py进行深拷贝
			2.fromkeys快速生成dict，前一个参数为一个可迭代对象，后者为value
			3.setdefault首先查询dict中是否存在这个值，如果不存在，会将这个键值对加入dict
			4.update传入一个可迭代对象，将这个可迭代对象与dict合并

set集合：集合是一个无序的，无重复的对象，可用于去重，传递一个可迭代对象，frozenset与set相比，set是可以变的，可以添加删除数据，frozenset是不可变的，set的性能很高，采用哈希算法，时间复杂度为1，set能进行-，&,|在于其中的魔法函数
set常用方法：add-添加值
		   different-生成一个新的对象，与减的作用类似
		   update-将两个set合并
		   issubset-判断前一个set是否在后一个set中，是返回True，否返回False

dict和list性能比较：dict查找的性能远远大于list，在list中随着list数据的增大 
				  查找时间会增大，在dict中查找元素不会随着dict的增大而增大
dict与set性能强大的原因：dict中的key或者set中的值必须是可hash的，可hash的意思就是不可变对象，str， fronzenset， tuple，都是可hash的，自己实现的类可以重载__hash__魔法函数，dict的存储空间花销大，但是查询快，dict的存储顺序和元素添加顺序有关（这个hash表中冲突有关）；添加数据有可能改变已有数据的顺序（这也和hash表中冲突有关）

python和Java中的变量本质不一样，Java在刚一开始就固定了变量类型，Python的变量本质就是一个指针，存储过程为先为变量划分一个内存地址，再将指针贴在变量上，而Java的变量就相当于将变量放进一种类型的盒子中
Python内部优化机制：对于小整数或者小字符串，Python会建立一个全局变量，当再调用这个变量时，会再调用之前已经存在的变量

Python的垃圾回收机制：引用计数，当给一个变量赋了一个值时，Python解释器的计数器就加1，再赋予另一个变量时再加1，运用del语句时，执行一次计数器就减1，当计数器为0时，Python解释器就回收内存地址，在类中，垃圾回收机制会重载__del__魔法函数，可以定制回收机制
一个经典的错误：在类中对于list或者dict指定默认值时，在引用这个类时，没有传递list或者dict的值，就有可能会改变默认值，这个默认值可以通过类.__init__.__defalut__查看，原因在于list或者dict可变且没有传递值
property:作为python的动态属性，加上property作为装饰器，可以将函数转换为类的属性，这样可以在这个函数中加入特定的逻辑，而且作为类的属性来使用，也可以使用setter作为装饰器来修改动态属性中的值
__getattr__:在查找不到属性的时候调用
__getattribute__:在调用类属性的时候无条件调用这个魔法函数中，所以尽量少重写这个魔法函数
属性描述符：在类中只要实现__get__,__set__,__delete__中的任意一个魔法函数，那么就实现了属性描述符，通过调用类的属性值，默认会先调用__set__中的函数，再调用__get__魔法函数，可以通过属性描述符来检查数据类型
python类中的查找机制：
	如果user是某个类的实例，那么user.age（以及等价的getattr(user,’age’)）
	首先调用__getattribute__。如果类定义了__getattr__方法，
	那么在__getattribute__抛出 AttributeError 的时候就会调用到__getattr__，
	而对于描述符(__get__）的调用，则是发生在__getattribute__内部的。
	user = User(), 那么user.age 顺序如下：

	（1）如果“age”是出现在User或其基类的__dict__中， 且age是data descriptor， 那么调用其__get__方法, 否则

	（2）如果“age”出现在user的__dict__中， 那么直接返回 obj.__dict__[‘age’]， 否则

	（3）如果“age”出现在User或其基类的__dict__中

	（3.1）如果age是non-data descriptor，那么调用其__get__方法， 否则

	（3.2）返回 __dict__[‘age’]

	（4）如果User有__getattr__方法，调用__getattr__方法，否则

	（5）抛出AttributeError

__new__魔法函数：是用来控制对象的生成过程，是在对象生成之前
__init__魔法函数：是用来完善对象的，但是如果__new__不返回对象，则不会调用__init__方法

元类编程：类其实是由type创建而成，python在创建类的时候，会首先查询metaclass，如果没有则查询父类中是否存在metaclass，如果不存在的情况下再通过type生成类，通过元类编程，可以将__new__重载在metaclass中，通过实现定义的一些规范来定义类的生成过程
元类编程之orm：打扰了，还没搞懂